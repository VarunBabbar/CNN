{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 1, 1]' is invalid for input of size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6b022f5f157b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0mkernel_shape3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_shape3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0mX_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_2_im2col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mim3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_shape3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbias3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_bn_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_shape3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitialize_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-6b022f5f157b>\u001b[0m in \u001b[0;36mmaxpool\u001b[0;34m(X, kernel_shape, stride)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_im2col\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_im2col\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_size0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_size1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_size2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 1, 1]' is invalid for input of size 9"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch # Used only for matrix multiplication\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import gc\n",
    "import tensorflow as tf # Used only to acquire MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X = []\n",
    "device = torch.device(\"cpu\")\n",
    "# Probably an input of images (eg MNIST or something)\n",
    "num_layers = 4\n",
    "dtype = torch.float\n",
    "torch.seed = 9\n",
    "np.random.seed(9)\n",
    "\n",
    "# Convolutional Neural Network written from scratch for basic classification tasks (eg MNIST / Cats and Dogs)\n",
    "# Can be used as a discriminator for a GAN as well\n",
    "\n",
    "# CNN_Engine is sort of complete. Now you have to clean up the code and make it bug free \n",
    "# Also, further optimisation to improve speed would be good. Use dictionaries wherever possible\n",
    "\n",
    "class CNN_Engine:\n",
    "    def __init__(self,num_layers,X,y,loss_type,num_epochs,bs,stride,dropout):\n",
    "        self.num_layers = num_layers\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.loss_type = loss_type      \n",
    "        self.num_epochs = num_epochs\n",
    "        self.bs = bs\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def cost_function(self,y_pred,y): # Assuming cross entropy loss\n",
    "        sumx = 0\n",
    "        for k in self.y:\n",
    "            sumx += -k*math.log(y_pred)\n",
    "        return sumx\n",
    "\n",
    "    def Relu(self,x):\n",
    "        if self.x > 0:\n",
    "            return self.x\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def MaxPool2d(self,X,kernel_size,stride):\n",
    "        return\n",
    "\n",
    "    def BatchNorm(self,X):\n",
    "        return (X-torch.mean(X)) / torch.std(X)\n",
    "    \n",
    "    def im2col2d(X,kernel,stride): # Assuming X and the kernel are 2D inputs\n",
    "        # We transform the input matrix X into a matrix Ω(x) such that the columns correspond to the \n",
    "        # set of elements that will be multiplied by the kernel in each sliding convolution operation\n",
    "        # Given x -> Ω(x), conv2d(x,kernel) = Ω(x)' * kernel where ' denotes a transpose operation\n",
    "\n",
    "        X = X.detach().numpy()\n",
    "        X = np.array(X)\n",
    "        kernel_shape = np.array(list(np.shape(kernel))).T\n",
    "        img_shape = np.array(list(np.shape(X))).T\n",
    "        a = np.empty((kernel_shape[0]*kernel_shape[1]*kernel_shape[2]))\n",
    "        output_matrix = np.reshape(a,(kernel_shape[0]*kernel_shape[1]*kernel_shape[2],1))\n",
    "        for k in range(0,img_shape[2],stride):\n",
    "             for j in range(0,img_shape[1],stride):\n",
    "                for i in range(0,img_shape[0],stride):\n",
    "                        try:\n",
    "                            vals = X[i:i+kernel_shape[0],j:j+kernel_shape[1],k:k+kernel_shape[2]]\n",
    "                            vals = np.reshape(vals,(int(np.shape(vals)[2]*np.shape(vals)[1]*np.shape(vals)[0]),1))\n",
    "                            output_matrix = np.hstack((output_matrix,vals))\n",
    "                        except:\n",
    "                            continue\n",
    "        \n",
    "        output_matrix = np.delete(output_matrix,0,1)\n",
    "        output_matrix = torch.FloatTensor(output_matrix)\n",
    "        return torch.nn.Parameter(output_matrix)\n",
    "\n",
    "    def conv2D(self,channels,X,stride,kernel_shape,padding = False): # filters = dimensionality of output space\n",
    "            # If padding is enabled, we pad the input with zeros such that the input size \n",
    "            # remains the same if weights with stride 1 are applied to the input\n",
    "            kernel = np.random.uniform(-0.1,0.1,size = (kernel_shape[0],kernel_shape[1],kernel_shape[2])) # Our input\n",
    "            kernel = torch.FloatTensor(kernel)\n",
    "            kernel.requires_grad = True\n",
    "            X = X.detach().numpy()\n",
    "            if padding:\n",
    "                if kernel_shape[1] % 2 == 0 and kernel_shape[2] % 2 == 0:\n",
    "                    X = np.pad(X,((0,0),(math.floor(kernel_shape[1]/2)-1,math.floor(kernel_shape[1]/2)),(math.floor(kernel_shape[2]/2),math.floor(kernel_shape[2]/2)-1)), 'symmetric')\n",
    "                elif kernel_shape[1] % 2 != 0 and kernel_shape[2] % 2 == 0:\n",
    "                    X = np.pad(X,((0,0),(math.floor(kernel_shape[1]/2),math.floor(kernel_shape[1]/2)),(math.floor(kernel_shape[2]/2),math.floor(kernel_shape[2]/2)-1)), 'symmetric')\n",
    "                elif kernel_shape[1] % 2 == 0 and kernel_shape[2] % 2 != 0:\n",
    "                    X = np.pad(X,((0,0),(math.floor(kernel_shape[1]/2)-1,math.floor(kernel_shape[1]/2)),(math.floor(kernel_shape[2]/2),math.floor(kernel_shape[2]/2))), 'symmetric')\n",
    "                else:\n",
    "                    X = np.pad(X,((0,0),(math.floor(kernel_shape[1]/2),math.floor(kernel_shape[1]/2)),(math.floor(kernel_shape[2]/2),math.floor(kernel_shape[2]/2))), 'symmetric')\n",
    "            X = torch.FloatTensor(X)\n",
    "            img_shape = np.transpose(np.array(list(np.shape(X))))\n",
    "            output_size1 = math.floor((img_shape[1] - kernel_shape[1])/(stride)) + 1\n",
    "            output_size2 = math.floor((img_shape[2] - kernel_shape[2])/(stride)) + 1\n",
    "            output_shape = [channels,output_size1,output_size2]\n",
    "            X_im2col = im2col2d(X,kernel,stride)\n",
    "            \n",
    "            weight = torch.reshape(kernel,(kernel_shape[0]*kernel_shape[1]*kernel_shape[2],1))\n",
    "            # weight consists of only one weight vector. But the dimensionality of output space has to be \n",
    "            # num_filters. So we need to stack weight vectors horizontally and create num_filters number of \n",
    "            # feature maps\n",
    "            for i in range(channels-1):\n",
    "                weight2 = np.random.uniform(-0.1,0.1,size = (kernel_shape[0]*kernel_shape[1]*kernel_shape[2],1)) # Our input\n",
    "                weight2 = torch.FloatTensor(weight2)\n",
    "                weight2.requires_grad = True \n",
    "                weight = torch.cat((weight2, weight),1) # do this num_filters - 1 number of times\n",
    "            conv_output = torch.t(X_im2col).mm(weight)\n",
    "            conv_output = torch.reshape(conv_output,(output_shape))\n",
    "            weight.retain_grad()\n",
    "            return torch.nn.Parameter(conv_output), torch.nn.Parameter(weight),X_im2col\n",
    "\n",
    "    def backprop_with_gradient_descent(self,y_pred,y,x):\n",
    "        return\n",
    "\n",
    "    def feedforward(self,x):\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "# I havent converted the code below into a CNN_Engine class, because the code below is for experimentation \n",
    "# The CNN trains, but it would be better to make it library-esque so that it can be run like PyTorch\n",
    "    \n",
    "def im2col2d(X,kernel,stride,im_needed = True,shape_specified = False): # Assuming X and the kernel are 2D inputs\n",
    "        # We transform the input matrix X into a matrix Ω(x) such that the columns correspond to the \n",
    "        # set of elements that will be multiplied by the kernel in each sliding convolution operation\n",
    "        # Given x -> Ω(x), conv2d(x,kernel) = Ω(x)' * kernel where ' denotes a transpose operation\n",
    "\n",
    "        X = X.detach().numpy()\n",
    "        X = np.array(X)\n",
    "        if not shape_specified: # If the kernel shape is not specified, then it is assumed that the argument kernel is a weight matrix\n",
    "            kernel_shape = kernel.shape\n",
    "        else: # If the kernel shape is specified, then it is assumed that the argument is the shape of the weight, not the weight itself\n",
    "            kernel_shape = kernel\n",
    "\n",
    "        img_shape = np.shape(X)\n",
    "        a = np.empty((kernel_shape[0]*kernel_shape[1]*kernel_shape[2]))\n",
    "        output_matrix = np.reshape(a,(kernel_shape[0]*kernel_shape[1]*kernel_shape[2],1))\n",
    "        q = 0\n",
    "        output_size1 = math.floor((img_shape[1] - kernel_shape[1])/(stride)) + 1\n",
    "        output_size2 = math.floor((img_shape[2] - kernel_shape[2])/(stride)) + 1\n",
    "        if im_needed:\n",
    "            indicator_dict = {}            # Map (i,j,k) to (p,q)  (i,j,k): (p,q)\n",
    "        coord_matrix = np.zeros((img_shape[0],img_shape[1],img_shape[2]),dtype='object')\n",
    "        for k in range(0,img_shape[2]):\n",
    "             for j in range(0,img_shape[1]):\n",
    "                for i in range(0,img_shape[0]):\n",
    "                    coord_matrix[i,j,k] = (i,j,k)\n",
    "                    \n",
    "        for k in range(0,img_shape[2],stride):\n",
    "             for j in range(0,img_shape[1],stride):\n",
    "                for i in range(0,img_shape[0],stride):\n",
    "                        try:\n",
    "                            vals = X[i:i+kernel_shape[0],j:j+kernel_shape[1],k:k+kernel_shape[2]]\n",
    "                            vals = np.reshape(vals,(int(np.shape(vals)[2]*np.shape(vals)[1]*np.shape(vals)[0]),1))\n",
    "                            output_matrix = np.hstack((output_matrix,vals))\n",
    "                            indices = coord_matrix[i:i+kernel_shape[0],j:j+kernel_shape[1],k:k+kernel_shape[2]]\n",
    "                            \n",
    "                            indices = np.reshape(indices,(int(np.shape(indices)[2]*np.shape(indices)[1]*np.shape(indices)[0])))                            \n",
    "                            coords = [(p,q) for p in range(len(indices))]\n",
    "                            d = dict(zip(coords,list(indices)))\n",
    "                            indicator_dict.update(d)\n",
    "                            q+=1\n",
    "                            \n",
    "                        except:\n",
    "                             continue\n",
    "        \n",
    "        if im_needed:\n",
    "            reversed_indicator_dict = dict()\n",
    "            for k,v in indicator_dict.items():\n",
    "                reversed_indicator_dict.setdefault(v, []).append(k) # Reversed mapping now in order to \n",
    "        \n",
    "        output_matrix = np.delete(output_matrix,0,1)\n",
    "        output_matrix = torch.FloatTensor(output_matrix)\n",
    "        if im_needed:\n",
    "            return torch.nn.Parameter(output_matrix),reversed_indicator_dict\n",
    "        else:\n",
    "            return torch.nn.Parameter(output_matrix),-1\n",
    "    \n",
    "def conv2D(self,channels,X,stride,kernel_shape,padding = False,initialize_weights = True,*args): # filters = dimensionality of output space\n",
    "            # If padding is enabled, we pad the input with zeros such that the input size \n",
    "            # remains the same if weights with stride 1 are applied to the input\n",
    "            \n",
    "            if initialize_weights:\n",
    "                kernel = np.random.uniform(-0.1,0.1,size = (kernel_shape[0],kernel_shape[1],kernel_shape[2])) # Our input\n",
    "             # Our input\n",
    "                kernel = torch.FloatTensor(kernel)\n",
    "                kernel.requires_grad = True\n",
    "            else:\n",
    "                kernel = args[0] # weights and bias must be given if initialise weights is disabled\n",
    "                bias = args[1]\n",
    "                kernel_shape = kernel.shape\n",
    "            \n",
    "            X = X.detach().numpy()\n",
    "            if padding: # Can only pad during initialization -> weights and input shapes cannot change during feedforward and backpropagation\n",
    "                if kernel_shape[1] % 2 == 0 and kernel_shape[2] % 2 == 0:\n",
    "                    X = np.pad(X,((0,0),(math.floor(kernel_shape[1]/2)-1,math.floor(kernel_shape[1]/2)),(math.floor(kernel_shape[2]/2),math.floor(kernel_shape[2]/2)-1)), 'symmetric')\n",
    "                elif kernel_shape[1] % 2 != 0 and kernel_shape[2] % 2 == 0:\n",
    "                    X = np.pad(X,((0,0),(math.floor(kernel_shape[1]/2),math.floor(kernel_shape[1]/2)),(math.floor(kernel_shape[2]/2),math.floor(kernel_shape[2]/2)-1)), 'symmetric')\n",
    "                elif kernel_shape[1] % 2 == 0 and kernel_shape[2] % 2 != 0:\n",
    "                    X = np.pad(X,((0,0),(math.floor(kernel_shape[1]/2)-1,math.floor(kernel_shape[1]/2)),(math.floor(kernel_shape[2]/2),math.floor(kernel_shape[2]/2))), 'symmetric')\n",
    "                else:\n",
    "                    X = np.pad(X,((0,0),(math.floor(kernel_shape[1]/2),math.floor(kernel_shape[1]/2)),(math.floor(kernel_shape[2]/2),math.floor(kernel_shape[2]/2))), 'symmetric')\n",
    "            \n",
    "            X = torch.FloatTensor(X)\n",
    "            \n",
    "            img_shape = X.shape\n",
    "            \n",
    "            output_size1 = math.floor((img_shape[1] - kernel_shape[1])/(stride)) + 1\n",
    "            output_size2 = math.floor((img_shape[2] - kernel_shape[2])/(stride)) + 1\n",
    "            output_shape = [channels,output_size1,output_size2]\n",
    "            \n",
    "            X_im2col,im = im2col2d(X,kernel,stride)\n",
    "            \n",
    "            \n",
    "            if initialize_weights:\n",
    "                weight = torch.reshape(kernel,(kernel_shape[0]*kernel_shape[1]*kernel_shape[2],1))\n",
    "                # weight consists of only one weight vector. But the dimensionality of output space has to be \n",
    "                # num_filters. So we need to stack weight vectors horizontally and create num_filters number of \n",
    "                # feature maps\n",
    "                for i in range(channels-1):\n",
    "                    weight2 = np.random.uniform(-0.1,0.1,size = (kernel_shape[0]*kernel_shape[1]*kernel_shape[2],1)) # Our input\n",
    "                    weight2 = torch.FloatTensor(weight2)\n",
    "                    weight2.requires_grad = True \n",
    "                    weight = torch.cat((weight2, weight),1) # do this num_filters - 1 number of times\n",
    "                conv_output = torch.t(X_im2col).mm(weight)\n",
    "                bias = torch.Tensor(np.random.uniform(-0.1,0.1,size = conv_output.shape))\n",
    "                conv_output += bias\n",
    "                conv_output = torch.reshape(conv_output,(output_shape))\n",
    "                return torch.nn.Parameter(conv_output), torch.nn.Parameter(weight),X_im2col,im, output_shape,bias\n",
    "            else:\n",
    "                # Since weights are already initialised, the relevant channels are already dictated in the architecture. \n",
    "                # Therefore, conv output is just a matmul \n",
    "                conv_output = torch.t(X_im2col).mm(kernel) + bias\n",
    "                return torch.nn.Parameter(conv_output),X_im2col\n",
    "                \n",
    "                \n",
    "            \n",
    "\n",
    "# For example, if you call out.backward() for some variable out that \n",
    "# involved x in its calculations then x.grad will hold ∂out/∂x      \n",
    "# kernel = np.array([[[1,1],[1,1]]]) # format = channels * rows * columns\n",
    "# X = np.array([[[1,2,3,1],[4,5,6,1],[7,8,9,1]]])\n",
    "def maxpool(X,kernel_shape,stride):\n",
    "    \n",
    "    X_im2col,im = im2col2d(X,kernel_shape,stride,im_needed = True,shape_specified = True)\n",
    "    output = torch.zeros((X.shape[1],1))\n",
    "    output_size0 = math.floor((X.shape[0] - kernel_shape[0])/(stride)) + 1\n",
    "    output_size1 = math.floor((X.shape[1] - kernel_shape[1])/(stride)) + 1\n",
    "    output_size2 = math.floor((X.shape[2] - kernel_shape[2])/(stride)) + 1\n",
    "\n",
    "    for j in range(X_im2col.shape[1]):\n",
    "        output[j] = max(X_im2col[:,j])\n",
    "    output = torch.reshape(output,(output_size0,output_size1,output_size2))\n",
    "    return output\n",
    "\n",
    "class MyReLU(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    We can implement our own custom autograd Functions by subclassing\n",
    "    torch.autograd.Function and implementing the forward and backward passes\n",
    "    which operate on Tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we receive a Tensor containing the input and return\n",
    "        a Tensor containing the output. ctx is a context object that can be used\n",
    "        to stash information for backward computation. You can cache arbitrary\n",
    "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.clamp(min=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input < 0] = 0\n",
    "        return grad_input\n",
    "    \n",
    "def softmax(y): # A bit lengthy for a simple softmax implementation but it was all I could do to avoid gradient related errors\n",
    "#     y = y.squeeze()\n",
    "    epsilon = 0.001\n",
    "    y = y.detach().numpy()\n",
    "    return torch.Tensor(np.exp(y)/(epsilon + sum(np.exp(y))))\n",
    "\n",
    "def BatchNorm(X): # (X - mu) / sigma\n",
    "    epsilon = 0.001  # To prevent overflow and ensure numerical stability\n",
    "    bn = (X - torch.mean(X)) / (torch.std(X)+epsilon)   \n",
    "    sigma.append(torch.std(X)+epsilon)\n",
    "    return bn\n",
    "    \n",
    "def conv_bn_relu(X,channels,stride,kernel_shape,padding,activation = 'sigmoid',initialize_weights = True,*args): # Refactoring conv_batchnorm_relu as one layer\n",
    "    if initialize_weights:\n",
    "        output_1,weights,X_im2col,im,output_shape,bias = conv2D(0,channels,X,stride,kernel_shape,padding,initialize_weights = True,*args) # conv\n",
    "    else:\n",
    "        output1,X_im2col = conv2D(0,channels,X,stride,kernel_shape,padding,initialize_weights = False,*args) # conv\n",
    "        \n",
    "    output_1 = BatchNorm(output_1) # batchnorm\n",
    "    if activation == 'sigmoid':\n",
    "        X_1 = sigmoid(output_1)\n",
    "    elif activation == 'relu':\n",
    "        X_1 = relu(output_1)\n",
    "    else:\n",
    "        X_1 = output_1\n",
    "    if initialize_weights:\n",
    "        return torch.nn.Parameter(X_1),torch.nn.Parameter(weights),torch.nn.Parameter(X_im2col),im,output_shape,bias\n",
    "    else:\n",
    "        return output1,X_im2col\n",
    "\n",
    "def flatten_and_dense(X,out_channels,activtation = 'sigmoid', initialise_weights = True,*args): \n",
    "    \"\"\" Flattens the input and outputs a fully connected dense layer after applying an activation function\"\"\" \n",
    "    shape = X.shape\n",
    "    X = torch.reshape(X,(shape[0]*shape[1]*shape[2],1)) # Flatten\n",
    "    if initialise_weights == True:\n",
    "        weights = torch.Tensor(np.random.uniform(-0.1,0.1, size = (out_channels,len(X))))\n",
    "        bias = torch.Tensor(np.random.uniform(-0.1,0.1, size = (out_channels,1)))\n",
    "    else:\n",
    "        weights = args[0]\n",
    "        bias = args[1]\n",
    "    if activation == 'sigmoid':\n",
    "        output = sigmoid(weights.mm(X) + bias)\n",
    "    else: # Only support sigmoid and relu for now\n",
    "        output = relu(weights.mm(X) + bias)\n",
    "    return output\n",
    "                                                                     \n",
    "def cross_entropy(y_pred,y):\n",
    "        epsilon = 0.001 # To prevent overflow and ensure numerical stability\n",
    "        return sum(-y*np.log(y_pred+epsilon))\n",
    "\n",
    "def sigmoid(X):\n",
    "    X = X.detach().numpy()\n",
    "    X = torch.FloatTensor((1/(1+(np.exp(-X)))))\n",
    "    return X\n",
    "\n",
    "def getIndexes(indicator_matrix, val): \n",
    "\n",
    "    ''' Get desired coordinates of val in an indicator matrix. \n",
    "    val will be in the form of ijk cartesian coordinates'''    \n",
    "    try:\n",
    "        return indicator_matrix[val]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "relu = MyReLU.apply\n",
    "\n",
    "padding = False # Mostly will never set this to true\n",
    "sigma = []\n",
    "num_examples = 250\n",
    "# y = np.random.randint(0,2,size = (10,1))\n",
    "y = np.zeros((10,num_examples))\n",
    "\n",
    "for i in range(y.shape[1]):\n",
    "    y[y_train[i],i] = 1\n",
    "y_input = y   \n",
    "y = Variable(torch.FloatTensor(y))\n",
    "y.requires_grad = False\n",
    "\n",
    "X_input = x_train[0:num_examples,:,:]\n",
    "X_input = torch.FloatTensor(X_input)\n",
    "\n",
    "input_dictionary = {}  # Dictionary of input data and their respective im2col keyed by the training sample number\n",
    "\n",
    "architecture = {}\n",
    "\n",
    "#### Architecture: Shape it as you want ####\n",
    "channels = 2\n",
    "\n",
    "X = X_input[0:1,:,:]\n",
    "y = torch.Tensor(y_input[:,0:1])\n",
    "\n",
    "stride = 1\n",
    "kernel_shape1 = (1,5,5)\n",
    "X_1,weights1,X_im2col,im1,output_shape1,bias1 = conv_bn_relu(X,channels,stride,kernel_shape1,padding,activation = \"relu\",initialize_weights = True)\n",
    "\n",
    "architecture['layer1'] = np.array([X_1,weights1,bias1,X_im2col,im1,output_shape1,kernel_shape1,stride],dtype = 'object')\n",
    "\n",
    "# # Experimental\n",
    "# im1 = im1.to_numpy()\n",
    "\n",
    "# for i in range(im1.shape[0]):\n",
    "#     for j in range(im1.shape[1]):\n",
    "#         im1[i,j] = im1[i,j].squeeze().squeeze()\n",
    "# im1 = im1.squeeze()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stride = 2\n",
    "kernel_shape2 = (channels,7,7)\n",
    "\n",
    "X_2,weights2,X_1_im2col,im2,output_shape2,bias2 = conv_bn_relu(X_1,channels,stride,kernel_shape2,padding,initialize_weights = True) # can change the number of channels to any integer value\n",
    "\n",
    "architecture['layer2'] = np.array([X_2,weights2,bias2,X_1_im2col,im2,output_shape2,kernel_shape2,stride],dtype = 'object')\n",
    "\n",
    "\n",
    "# # Experimental\n",
    "# im2 = im2.to_numpy()\n",
    "# for i in range(im2.shape[0]):\n",
    "#     for j in range(im2.shape[1]):\n",
    "#         im2[i,j] = im2[i,j].squeeze().squeeze()\n",
    "# im2 = im2.squeeze()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stride = 3\n",
    "kernel_shape3 = (channels,8,8)\n",
    "a = maxpool(X_2,kernel_shape3,stride)\n",
    "channels = 10\n",
    "X_3,weights3,X_2_im2col,im3,output_shape3,bias3 = conv_bn_relu(X_2,channels,stride,kernel_shape3,padding,initialize_weights = True)\n",
    "architecture['layer3'] = np.array([X_3,weights3,bias3,X_2_im2col,im3,output_shape3,kernel_shape3,stride],dtype = 'object')\n",
    "\n",
    "\n",
    "print(X_3.shape)\n",
    "# kernel_shape = (10,1,1)\n",
    "# X_4,weights4,X_3_im2col,im4 = conv_bn_relu(X_3,channels,stride,kernel_shape,padding)\n",
    "\n",
    "# kernel_shape = (10,2,2)\n",
    "# X_5,weights5,X_4_im2col = conv_bn_relu(X_4,channels,stride,kernel_shape,padding)\n",
    "\n",
    "# kernel_shape = (10,1,1) # no of channels in kernel must be the same as that in the input image, i.e. X_5 in this case\n",
    "# Y,weights6, X_5_im2col = conv_bn_relu(X_5,channels,stride,kernel_shape,padding)\n",
    "# Y = X_2\n",
    "# X_2 = X_2.squeeze()\n",
    "\n",
    "\n",
    "##### Experimental: Implementing Backpropagation \n",
    "y_pred = softmax(X_3)\n",
    "y_pred = torch.reshape(y_pred,y.size())\n",
    "loss = Variable(cross_entropy(y_pred.squeeze(),y.squeeze()))\n",
    "weights2.requires_grad = False\n",
    "weights1.requires_grad = False\n",
    "weights3.requires_grad = False\n",
    "print(\"Hi\")\n",
    "\n",
    "dropout = 0.2\n",
    "epochs = 21\n",
    "bs = 10\n",
    "arr = []\n",
    "epsilon = 0.01\n",
    "\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.99\n",
    "\n",
    "def adam(g,beta_1,beta_2,m,v,t):\n",
    "    g = g.detach().numpy()\n",
    "    m = m.detach().numpy()\n",
    "    v = v.detach().numpy()\n",
    "    m = beta_1 * m + (1 - beta_1) * g\n",
    "    v = beta_2 * v + (1 - beta_2) * np.power(g, 2)\n",
    "    m_hat = m / (1 - np.power(beta_1, t)) + (1 - beta_1) * g / (1 - np.power(beta_1, t))\n",
    "    v_hat = v / (1 - np.power(beta_2, t))\n",
    "    grad = lr * m_hat / (np.sqrt(v_hat) + epsilon)\n",
    "    return torch.Tensor(grad),torch.Tensor(m),torch.Tensor(v)\n",
    "\n",
    "for epoch in range(epochs): # training + backpropagation. Problem: too slow -> need to speed it up\n",
    "    clip = 5\n",
    "    lr_multiplier = 0.2\n",
    "    stride1 = 1\n",
    "    stride2 = 2 \n",
    "    stride3 = 3\n",
    "\n",
    "    gc.collect()\n",
    "#     lr = 0.05\n",
    "    lr = min(0.2,0.01*np.exp(lr_multiplier*epoch))\n",
    "    \n",
    "    exp = 200\n",
    "    y = np.zeros((10,exp))\n",
    "    x_input = x_test[0:exp,:,:]\n",
    "    x_input = torch.FloatTensor(x_input)\n",
    "    val_loss = 0\n",
    "    num_correct = 0\n",
    "    for i in range(y.shape[1]):\n",
    "        y[y_test[i],i] = 1\n",
    "        y_val = torch.FloatTensor(y)\n",
    "    for index in range(exp):\n",
    "        X = BatchNorm(x_input[index,:,:])\n",
    "        y = np.array(torch.Tensor(y_val[:,index]))\n",
    "        X = torch.reshape(X,(1,X.shape[0],X.shape[1]))\n",
    "        # X = torch.reshape(y,(1,X.shape[0],X.shape[1]))\n",
    "        X_im2col,imX1 = im2col2d(X,kernel_shape1,stride1,im_needed = False,shape_specified = True)\n",
    "        X_1 = relu(BatchNorm(torch.t(X_im2col).mm(weights1) + bias1))\n",
    "        X_1 = torch.reshape(X_1,output_shape1)\n",
    "        X_1_im2col, imX2 = im2col2d(X_1,kernel_shape2,stride2,im_needed = False,shape_specified = True)\n",
    "        X_2 = relu(BatchNorm(torch.t(X_1_im2col).mm(weights2) + bias2))\n",
    "        X_2 = torch.reshape(X_2,output_shape2)\n",
    "        X_2_im2col, imX3 = im2col2d(X_2,kernel_shape3,stride3,im_needed = False,shape_specified = True)\n",
    "        X_3 = torch.t(X_2_im2col).mm(weights3) + bias3\n",
    "        X_x = X_3.squeeze()\n",
    "        y_pred = np.array(softmax(X_x))\n",
    "        val_loss += cross_entropy(y_pred.squeeze(),y.squeeze())\n",
    "        prediction = np.argmax(y_pred,axis=0)\n",
    "        actual = np.argmax(y,axis=0)\n",
    "    #     imshow(np.array(X.squeeze()))\n",
    "    #     print(\"Prediction is: {}\".format(prediction))\n",
    "        if prediction == actual:\n",
    "            num_correct += 1\n",
    "    accuracy = num_correct / exp\n",
    "    accuracy *= 100\n",
    "    \n",
    "    arr.append(loss)\n",
    "    loss = 0\n",
    "    # forward_propagation\n",
    "#     for i in architecture:\n",
    "#         X_i,weightsi,biasi,X_i_im2col,imi,output_shapei,kernel_shapei,stridei = architecture[i]\n",
    "#         X_i1 = relu(BatchNorm(torch.t(X_i_im2col).mm(weightsi)))\n",
    "#         X_i1 = torch.reshape(X_i1,output_shapei)\n",
    "#         architecture[i][0] = X_i1\n",
    "    t = 1\n",
    "    \n",
    "    # Initialising first and second moments for each gradient and bias matrix in each layer\n",
    "    grad_weights3 = torch.zeros(weights3.size())\n",
    "    grad_weights2 = torch.zeros(weights2.size())\n",
    "    grad_weights1 = torch.zeros(weights1.size())\n",
    "    grad_bias3 = torch.zeros(bias3.size())\n",
    "    grad_bias2 = torch.zeros(bias2.size())\n",
    "    grad_bias1 = torch.zeros(bias1.size())\n",
    "    bias3 = torch.zeros(bias3.size())\n",
    "    bias2 = torch.zeros(bias2.size())\n",
    "    bias1 = torch.zeros(bias1.size()) \n",
    "    \n",
    "    m3 = torch.zeros(weights3.size())\n",
    "    v3 = torch.zeros(weights3.size())\n",
    "    m2 = torch.zeros(weights2.size())\n",
    "    v2 = torch.zeros(weights2.size())\n",
    "    m1 = torch.zeros(weights1.size())\n",
    "    v1 = torch.zeros(weights1.size())\n",
    "    m3b = torch.zeros(bias3.size())\n",
    "    v3b = torch.zeros(bias3.size())\n",
    "    m2b = torch.zeros(bias2.size())\n",
    "    v2b = torch.zeros(bias2.size())\n",
    "    m1b = torch.zeros(bias1.size())\n",
    "    v1b = torch.zeros(bias1.size())\n",
    "    \n",
    "    for j in range(num_examples):\n",
    "        sigma = []  # Collecting the sigmas from the BatchNorm layer for the purposes of gradient descent\n",
    "        # Y = (X - mu) /sigma\n",
    "        # dY_dX = (1/sigma)*ones(X.shape)\n",
    "        if j%bs == 0 or j==num_examples-1 and j != 0: \n",
    "            if j%10 == 0:\n",
    "                print(\"Example: {}\".format(j))\n",
    "            # Dropout: Not implemented yet\n",
    "            \n",
    "#             grad_weights3 = torch.Tensor(grad_weights3)\n",
    "#             grad_weights3 = np.array(grad_weights3.detach().numpy())\n",
    "#             grad_weights2 = np.array(grad_weights2.detach().numpy())\n",
    "#             grad_weights1 = np.array(grad_weights1.detach().numpy())\n",
    "#             grad_bias3 = np.array(grad_bias3.detach().numpy())\n",
    "#             grad_bias2 = np.array(grad_bias2.detach().numpy())\n",
    "#             grad_bias1 = np.array(grad_bias1.detach().numpy())\n",
    "#             # Dropout to prevent overfitting\n",
    "#             indices_weights3 = np.random.choice(np.arange(grad_weights3.size), replace=False, size=int(grad_weights3.size * dropout))\n",
    "#             indices_weights2 = np.random.choice(np.arange(grad_weights2.size), replace=False, size=int(grad_weights2.size * dropout))\n",
    "#             indices_weights1 = np.random.choice(np.arange(grad_weights1.size), replace=False, size=int(grad_weights1.size * dropout))\n",
    "#             indices_bias3 = np.random.choice(np.arange(grad_bias3.size), replace=False, size=int(grad_bias3.size * dropout))\n",
    "#             indices_bias2 = np.random.choice(np.arange(grad_bias2.size), replace=False, size=int(grad_bias2.size * dropout))\n",
    "#             indices_bias1 = np.random.choice(np.arange(grad_bias1.size), replace=False, size=int(grad_bias1.size * dropout))\n",
    "#             print(indices_weights3)\n",
    "#             grad_weights3[indices_weights3] = 0\n",
    "#             grad_weights2[indices_weights2] = 0\n",
    "#             grad_weights1[indices_weights1] = 0\n",
    "#             grad_bias3[grad_bias3] = 0\n",
    "#             grad_bias2[grad_bias2] = 0\n",
    "#             grad_bias1[grad_bias1] = 0\n",
    "             \n",
    "            # Adam optimiser\n",
    "            q3,m3,v3 = adam(grad_weights3/bs,beta_1,beta_2,m3,v3,t)\n",
    "            q2,m2,v2 = adam(grad_weights2/bs,beta_1,beta_2,m2,v2,t)\n",
    "            q1,m1,v1 = adam(grad_weights1/bs,beta_1,beta_2,m1,v1,t)\n",
    "            qb3,m3b,v3b = adam(grad_bias3/bs,beta_1,beta_2,m3b,v3b,t)\n",
    "            qb2,m2b,v2b = adam(grad_bias2/bs,beta_1,beta_2,m2b,v2b,t)\n",
    "            qb1,m1b,v1b = adam(grad_bias1/bs,beta_1,beta_2,m1b,v1b,t)\n",
    "\n",
    "#             qb3 = 0\n",
    "#             qb2 = 0\n",
    "#             qb1 = 0\n",
    "            weights1 -= q1\n",
    "            bias1 -= qb1\n",
    "            \n",
    "            weights2 -= q2\n",
    "            bias2 -= qb2\n",
    "            \n",
    "            bias3 -= qb3\n",
    "            weights3 -= q3\n",
    "            \n",
    "            grad_weights3 = torch.zeros(grad_weights3.size())\n",
    "            grad_weights2 = torch.zeros(grad_weights2.size())\n",
    "            grad_weights1 = torch.zeros(grad_weights1.size())\n",
    "            grad_bias3 = torch.zeros(grad_bias3.size())\n",
    "            grad_bias2 = torch.zeros(grad_bias2.size())\n",
    "            grad_bias1 = torch.zeros(grad_bias1.size())\n",
    "            t+= 1\n",
    "        \n",
    "        # Feedforward\n",
    "        X = BatchNorm(X_input[j:j+1,:,:])\n",
    "        y = torch.Tensor(y_input[:,j:j+1])\n",
    "        X_im2col,imX1 = im2col2d(X,kernel_shape1,stride1,im_needed = False,shape_specified = True)\n",
    "        X_1 = relu(BatchNorm(torch.t(X_im2col).mm(weights1) + bias1))\n",
    "        X_1 = torch.reshape(X_1,output_shape1)\n",
    "        X_1_im2col, imX2 = im2col2d(X_1,kernel_shape2,stride2,im_needed = False,shape_specified = True)\n",
    "        X_2 = relu(BatchNorm(torch.t(X_1_im2col).mm(weights2) + bias2))\n",
    "        X_2 = torch.reshape(X_2,output_shape2)\n",
    "        X_2_im2col, imX3 = im2col2d(X_2,kernel_shape3,stride3,im_needed = False,shape_specified = True)\n",
    "        X_3 = torch.t(X_2_im2col).mm(weights3) + bias3\n",
    "        X_x = X_3.squeeze()\n",
    "        y_pred = softmax(X_x)\n",
    "        \n",
    "        y_pred = torch.reshape(y_pred,y.size())\n",
    "\n",
    "        loss += Variable(cross_entropy(y_pred.squeeze(),y.squeeze()),requires_grad=True)\n",
    "\n",
    "        ## BACKPROPAGATION ##\n",
    "        \n",
    "        dz_dX3 = y_pred - y     # Gradient of loss function wrt last layer output before softmax\n",
    "        \n",
    "        dz_dX3[dz_dX3 > clip] = 0 # Gradient clipping\n",
    "        dz_dX3[dz_dX3 < -clip] = 0 # Gradient clipping\n",
    "#         dz_dX3[torch.t(X_3) <= 0.000001] = 0     # For ReLu\n",
    "\n",
    "#         dz_dX3 = sigmoid(dz_dX3)*(1-sigmoid(dz_dX3))  # for sigmoid\n",
    "\n",
    "        dz_db3 = torch.t(dz_dX3)\n",
    "        # ' = derivative\n",
    "        # X3 = sigmoid(bn(X2im2col*weights3))\n",
    "        # dX3_dX2im2col = sigmoid'(weights3)\n",
    "        dz_dweights3 = (dz_dX3).mm(torch.t(X_2_im2col))    # dz_dweights3 = dz_dX3 * dX3_dweights3  (chain rule)\n",
    "        dz_dweights3[dz_dweights3 > clip] = 0  # Gradient Clipping\n",
    "        dz_dweights3[dz_dweights3 < -clip] = 0 # Gradient Clipping\n",
    "#         dz_dweights3 *= sigma[2]\n",
    "        gc.collect()\n",
    "\n",
    "        Y = weights3.mm(dz_dX3) # Y is the same shape as X_2im2col -> dz_dX2 (im2col version) = dz_dX3 * dX3_dX2im2col = Y as dX3_dX2im2col = weights3\n",
    "        # might need to do sigmoid'(weights3) or weights3()\n",
    "        \n",
    "        # dz_dX | (i,j,k) = sum (Y) at all locations (p,q) in X_2im2col where X_2(i,j,k) is placed. Makes sense coz Y is the im2col version of dz_dX2\n",
    " \n",
    "        dz_dX2 = torch.zeros(X_2.size())\n",
    "        \n",
    "        for i in range(np.shape(X_2)[0]):\n",
    "            for j in range(np.shape(X_2)[1]):\n",
    "                for k in range(np.shape(X_2)[2]):\n",
    "                    idxs = getIndexes(im3,(i,j,k))\n",
    "                    dz_dX2[i,j,k] = sum([Y[i[0],i[1]] for i in idxs])\n",
    "#         dz_dX2[X_2 <= 0.000001] = 0\n",
    "        dz_dX2 = torch.reshape(dz_dX2,(np.shape(X_2)[1]*np.shape(X_2)[2],-1))\n",
    "#         dz_dX2[dz_dX2 < 0] = 0        # For ReLu\n",
    "        \n",
    "        dz_dX2[dz_dX2 > clip] = 0  # Gradient Clipping\n",
    "        dz_dX2[dz_dX2 < -clip] = 0 # Gradient Clipping\n",
    "#         dz_dX2 = sigmoid(dz_dX2)*(1-sigmoid(dz_dX2))    #for sigmoid\n",
    "\n",
    "        dz_db2 = dz_dX2\n",
    "        \n",
    "        # ' = derivative\n",
    "        # X2 = sigmoid(bn(X1im2col*weights2))\n",
    "        # dX2_dX1im2col = X1im2col*sigmoid'(weights2)\n",
    "\n",
    "        dz_dweights2 = X_1_im2col.mm(dz_dX2)    \n",
    "        dz_dweights2[dz_dweights2 > clip] = 0  # Gradient Clipping\n",
    "        dz_dweights2[dz_dweights2 < -clip] = 0 # Gradient Clipping\n",
    "#         dz_dweights2 *= sigma[1]\n",
    "\n",
    "        Y = weights2.mm(torch.t(dz_dX2))\n",
    "\n",
    "        dz_dX1 = torch.zeros(X_1.size())\n",
    "\n",
    "        for i in range(np.shape(X_1)[0]):\n",
    "            for j in range(np.shape(X_1)[1]):\n",
    "                for k in range(np.shape(X_1)[2]): \n",
    "                    idxs = getIndexes(im2,(i,j,k))\n",
    "\n",
    "                    dz_dX1[i,j,k] = sum([Y[p[0],p[1]] for p in idxs])\n",
    "\n",
    "#         dz_dX1[X_1 <= 0.000001] = 0\n",
    "        dz_dX1 = torch.reshape(dz_dX1,(np.shape(X_1)[1]*np.shape(X_1)[2],-1))\n",
    "\n",
    "        gc.collect()\n",
    "        \n",
    "#         dz_dX1[dz_dX1 < 0] = 0 # For Relu\n",
    "        \n",
    "        dz_dX1[dz_dX1 > clip] = 0 # Gradient clipping\n",
    "        dz_dX1[dz_dX1 < -clip] = 0 # Gradient clipping\n",
    "        \n",
    "#         dz_dX1 = sigmoid(dz_dX1)*(1-sigmoid(dz_dX1)) # For sigmoid\n",
    "\n",
    "        dz_db1 = dz_dX1\n",
    "        \n",
    "\n",
    "        dz_dweights1 = X_im2col.mm(dz_dX1)\n",
    "        dz_dweights1[dz_dweights1 > clip] = 0  # Gradient Clipping\n",
    "        dz_dweights1[dz_dweights1 < -clip] = 0 # Gradient Clipping\n",
    "#         dz_dweights1 *= sigma[0]\n",
    "        \n",
    "        grad_weights3 += torch.t(dz_dweights3)\n",
    "        grad_weights2 += dz_dweights2\n",
    "        grad_weights1 += dz_dweights1\n",
    "        grad_bias3 += dz_db3\n",
    "        grad_bias2 += dz_db2\n",
    "        grad_bias1 += dz_db1\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    print(\"Training Loss: {}\".format(loss/num_examples)) \n",
    "    print(\"Validation Accuracy: {} %\".format(accuracy))\n",
    "    print(\"Validation Loss: {} %\".format(val_loss/exp))\n",
    "    \n",
    "#         grad_weights3 = 0\n",
    "#         grad_weights2 = 0\n",
    "#         grad_weights1 = 0\n",
    "#         grad_bias3 = 0\n",
    "#         grad_bias2 = 0\n",
    "#         grad_bias1 = 0\n",
    "\n",
    "#### Architecture: Shape it as you want ####\n",
    "\n",
    "# Architecture\n",
    "# conv batchnorm relu (stride 2, 10 feature maps) - > 16\n",
    "# conv batchnorm relu (stride 2, 10 feature maps) - > 8\n",
    "# conv batchnorm relu (stride 2, 10 feature maps) - > 4\n",
    "# conv batchnorm relu (stride 2, 10 feature maps) - > 2\n",
    "# conv batchnorm relu (stride 2, 10 feature maps) - > 1\n",
    "# softmax\n",
    "# y.squeeze()\n",
    "\n",
    "# We essentially only want the gradient of the loss with respect to the weights, so we can perform grad descent.\n",
    "# We don't need anything else!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradients of a: 1.50 and b: 0.50\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([1.5], requires_grad=True)\n",
    "a = torch.nn.Parameter(torch.tensor([2.]))\n",
    "b = torch.nn.Parameter(torch.tensor([10.]))\n",
    "y = x*a\n",
    "z = y+0.5*b\n",
    "temp = z.backward()\n",
    "print('gradients of a: %0.2f and b: %0.2f' % (a.grad.item(), b.grad.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Prediction is: 9\n",
      "1\n",
      "Prediction is: 0\n",
      "2\n",
      "Prediction is: 8\n",
      "3\n",
      "Prediction is: 3\n",
      "4\n",
      "Prediction is: 1\n",
      "5\n",
      "Prediction is: 9\n",
      "6\n",
      "Prediction is: 7\n",
      "7\n",
      "Prediction is: 9\n",
      "8\n",
      "Prediction is: 1\n",
      "9\n",
      "Prediction is: 0\n",
      "10\n",
      "Prediction is: 4\n",
      "11\n",
      "Prediction is: 1\n",
      "12\n",
      "Prediction is: 9\n",
      "13\n",
      "Prediction is: 9\n",
      "14\n",
      "Prediction is: 7\n",
      "15\n",
      "Prediction is: 9\n",
      "16\n",
      "Prediction is: 2\n",
      "17\n",
      "Prediction is: 4\n",
      "18\n",
      "Prediction is: 9\n",
      "19\n",
      "Prediction is: 1\n",
      "20\n",
      "Prediction is: 3\n",
      "21\n",
      "Prediction is: 7\n",
      "22\n",
      "Prediction is: 9\n",
      "23\n",
      "Prediction is: 4\n",
      "24\n",
      "Prediction is: 9\n",
      "25\n",
      "Prediction is: 1\n",
      "26\n",
      "Prediction is: 6\n",
      "27\n",
      "Prediction is: 1\n",
      "28\n",
      "Prediction is: 3\n",
      "29\n",
      "Prediction is: 8\n",
      "30\n",
      "Prediction is: 1\n",
      "31\n",
      "Prediction is: 2\n",
      "32\n",
      "Prediction is: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYFBgYGBwkIBgcJBwYGCAsICQoKCgoKBggLDAsKDAkKCgr/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/AP5/6+6/g5/wb5ftl+O/gP4f/aT+O/xg+CvwA8IeLo0k8Jaj8fPiOmgNrCOnmIYY1hmcFo8uqyBGKLvxtKk4P7Sf/BBz9vr4A/DqX43+A9K8I/Gv4eW9v5tz8QPgP4oTxJpsAwpbeI1S4UKHVmcw7Ap3bsAkfGVFftD/AMF8LT48ftK/8E/v+CdHwj+F/wAOPE/jHXtQ+AaeIL3TfC2kz3s1050jQ1Mn2W2jY/IPMO4DCiVhwM5/Jb4X/HD9o39lnxpdaj8HPix4y+H2v21x5OoP4f1q60y5SSGTPlyiJkbKOv3W6MOmRXK+JvE3iLxp4k1Dxj4w1281TV9Wvpb3VNT1C5aa4vLmVy8s0sjks7u7MzMSSSSScmqNft5+z3/wcpftBftI/DX4R/8ABP8A/Zm0XwB8CfHtl4P0zwzb/F/xvqIu7O7u7KKFY7NAbYrYRXjQKm6TzgjSKvpKvzl/wdQ/s2Xnwd/4KJaP8bpfhYfCL/GX4c6Z4p17RUlidLPXSGg1G33ROyu6vHG7uvyu8rMN2dx/NCilR3jcSRsVZTlWBwQa6f4pfG/40/HK/wBN1X41/F7xR4wutH0uPTNIufFPiC51CSxsoyzJbQtO7mKFSzERrhQWOBya5ev/2Q==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "Prediction is: 8\n",
      "34\n",
      "Prediction is: 0\n",
      "35\n",
      "Prediction is: 4\n",
      "36\n",
      "Prediction is: 2\n",
      "37\n",
      "Prediction is: 1\n",
      "38\n",
      "Prediction is: 1\n",
      "39\n",
      "Prediction is: 1\n",
      "40\n",
      "Prediction is: 1\n",
      "41\n",
      "Prediction is: 8\n",
      "42\n",
      "Prediction is: 3\n",
      "43\n",
      "Prediction is: 4\n",
      "44\n",
      "Prediction is: 9\n",
      "45\n",
      "Prediction is: 9\n",
      "46\n",
      "Prediction is: 3\n",
      "47\n",
      "Prediction is: 0\n",
      "48\n",
      "Prediction is: 4\n",
      "49\n",
      "Prediction is: 2\n",
      "50\n",
      "Prediction is: 4\n",
      "51\n",
      "Prediction is: 4\n",
      "52\n",
      "Prediction is: 9\n",
      "53\n",
      "Prediction is: 2\n",
      "54\n",
      "Prediction is: 1\n",
      "55\n",
      "Prediction is: 7\n",
      "56\n",
      "Prediction is: 2\n",
      "57\n",
      "Prediction is: 4\n",
      "58\n",
      "Prediction is: 9\n",
      "59\n",
      "Prediction is: 4\n",
      "60\n",
      "Prediction is: 4\n",
      "61\n",
      "Prediction is: 0\n",
      "62\n",
      "Prediction is: 9\n",
      "63\n",
      "Prediction is: 9\n",
      "64\n",
      "Prediction is: 2\n",
      "65\n",
      "Prediction is: 2\n",
      "66\n",
      "Prediction is: 3\n",
      "67\n",
      "Prediction is: 3\n",
      "68\n",
      "Prediction is: 9\n",
      "69\n",
      "Prediction is: 3\n",
      "70\n",
      "Prediction is: 3\n",
      "71\n",
      "Prediction is: 7\n",
      "72\n",
      "Prediction is: 3\n",
      "73\n",
      "Prediction is: 7\n",
      "74\n",
      "Prediction is: 8\n",
      "75\n",
      "Prediction is: 1\n",
      "76\n",
      "Prediction is: 2\n",
      "77\n",
      "Prediction is: 9\n",
      "78\n",
      "Prediction is: 6\n",
      "79\n",
      "Prediction is: 6\n",
      "80\n",
      "Prediction is: 4\n",
      "81\n",
      "Prediction is: 9\n",
      "82\n",
      "Prediction is: 3\n",
      "83\n",
      "Prediction is: 1\n",
      "84\n",
      "Prediction is: 0\n",
      "85\n",
      "Prediction is: 6\n",
      "86\n",
      "Prediction is: 9\n",
      "87\n",
      "Prediction is: 8\n",
      "88\n",
      "Prediction is: 9\n",
      "89\n",
      "Prediction is: 6\n",
      "90\n",
      "Prediction is: 9\n",
      "91\n",
      "Prediction is: 6\n",
      "92\n",
      "Prediction is: 1\n",
      "93\n",
      "Prediction is: 8\n",
      "94\n",
      "Prediction is: 0\n",
      "95\n",
      "Prediction is: 3\n",
      "96\n",
      "Prediction is: 9\n",
      "97\n",
      "Prediction is: 1\n",
      "98\n",
      "Prediction is: 3\n",
      "99\n",
      "Prediction is: 6\n",
      "100\n",
      "Prediction is: 7\n",
      "101\n",
      "Prediction is: 9\n",
      "102\n",
      "Prediction is: 9\n",
      "103\n",
      "Prediction is: 9\n",
      "104\n",
      "Prediction is: 7\n",
      "105\n",
      "Prediction is: 9\n",
      "106\n",
      "Prediction is: 4\n",
      "107\n",
      "Prediction is: 9\n",
      "108\n",
      "Prediction is: 6\n",
      "109\n",
      "Prediction is: 3\n",
      "110\n",
      "Prediction is: 7\n",
      "111\n",
      "Prediction is: 4\n",
      "112\n",
      "Prediction is: 6\n",
      "113\n",
      "Prediction is: 3\n",
      "114\n",
      "Prediction is: 9\n",
      "115\n",
      "Prediction is: 9\n",
      "116\n",
      "Prediction is: 9\n",
      "117\n",
      "Prediction is: 8\n",
      "118\n",
      "Prediction is: 8\n",
      "119\n",
      "Prediction is: 7\n",
      "120\n",
      "Prediction is: 8\n",
      "121\n",
      "Prediction is: 0\n",
      "122\n",
      "Prediction is: 3\n",
      "123\n",
      "Prediction is: 6\n",
      "124\n",
      "Prediction is: 8\n",
      "125\n",
      "Prediction is: 9\n",
      "126\n",
      "Prediction is: 7\n",
      "127\n",
      "Prediction is: 9\n",
      "128\n",
      "Prediction is: 7\n",
      "129\n",
      "Prediction is: 1\n",
      "130\n",
      "Prediction is: 9\n",
      "131\n",
      "Prediction is: 4\n",
      "132\n",
      "Prediction is: 2\n",
      "133\n",
      "Prediction is: 9\n",
      "134\n",
      "Prediction is: 3\n",
      "135\n",
      "Prediction is: 8\n",
      "136\n",
      "Prediction is: 1\n",
      "137\n",
      "Prediction is: 1\n",
      "138\n",
      "Prediction is: 2\n",
      "139\n",
      "Prediction is: 1\n",
      "140\n",
      "Prediction is: 4\n",
      "141\n",
      "Prediction is: 3\n",
      "142\n",
      "Prediction is: 9\n",
      "143\n",
      "Prediction is: 7\n",
      "144\n",
      "Prediction is: 3\n",
      "145\n",
      "Prediction is: 4\n",
      "146\n",
      "Prediction is: 3\n",
      "147\n",
      "Prediction is: 4\n",
      "148\n",
      "Prediction is: 0\n",
      "149\n",
      "Prediction is: 9\n",
      "150\n",
      "Prediction is: 3\n",
      "151\n",
      "Prediction is: 6\n",
      "152\n",
      "Prediction is: 9\n",
      "153\n",
      "Prediction is: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYFBgYGBwkIBgcJBwYGCAsICQoKCgoKBggLDAsKDAkKCgr/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/AP5/69J/ZM/ZE/aG/bh+Numfs9fsxfDe88T+KNTVpEtLYhI7a3THmXM8rEJDCm4bnYgZZVGWZQfsv/gpR/wQJsv+CcX7GS/tIa9+3Z4P8Z+MdJ8c6d4T8b/DzQNFKpoup3VjLem2S9NyzTzJCkchje3hJjdnyNoV/wA66K/dyfw/+0L/AMEPv+CH/gmx/Y1/Zq8Uar8bv2hvDA8QfEn4t+GfCN7cjwbpM0SSwW8tykbC3uI4rmOKNSVRJFuZRlgjN+I+ufGP4teJvDWo+DfEnxO1/UNJ1fxI3iHVtOvdXmlhvtXKOh1CZGYiW52SSr5zZfErjPzNnm6K/pq+GNt8cP24Yv2P/wDgpr/wT5/ba8M+C/CngH4e6N4Y/aQ0PVvGEkNvZWtr5T3Flc27RiKaRWkvYlaYR5LQyxkKQ1fin/wXj+I/7KXxa/4Kr/Fj4gfsaXdhdeDNQ1WBn1DRoUSwvtSW2iW+uLbYArxyXKyt5g4lcvICyuGPyDRRRRX/2Q==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\n",
      "Prediction is: 0\n",
      "155\n",
      "Prediction is: 2\n",
      "156\n",
      "Prediction is: 9\n",
      "157\n",
      "Prediction is: 9\n",
      "158\n",
      "Prediction is: 4\n",
      "159\n",
      "Prediction is: 9\n",
      "160\n",
      "Prediction is: 4\n",
      "161\n",
      "Prediction is: 6\n",
      "162\n",
      "Prediction is: 4\n",
      "163\n",
      "Prediction is: 4\n",
      "164\n",
      "Prediction is: 9\n",
      "165\n",
      "Prediction is: 9\n",
      "166\n",
      "Prediction is: 3\n",
      "167\n",
      "Prediction is: 4\n",
      "168\n",
      "Prediction is: 8\n",
      "169\n",
      "Prediction is: 9\n",
      "170\n",
      "Prediction is: 9\n",
      "171\n",
      "Prediction is: 7\n",
      "172\n",
      "Prediction is: 3\n",
      "173\n",
      "Prediction is: 9\n",
      "174\n",
      "Prediction is: 2\n",
      "175\n",
      "Prediction is: 7\n",
      "176\n",
      "Prediction is: 0\n",
      "177\n",
      "Prediction is: 2\n",
      "178\n",
      "Prediction is: 4\n",
      "179\n",
      "Prediction is: 1\n",
      "180\n",
      "Prediction is: 1\n",
      "181\n",
      "Prediction is: 1\n",
      "182\n",
      "Prediction is: 6\n",
      "183\n",
      "Prediction is: 9\n",
      "184\n",
      "Prediction is: 1\n",
      "185\n",
      "Prediction is: 9\n",
      "186\n",
      "Prediction is: 7\n",
      "187\n",
      "Prediction is: 8\n",
      "188\n",
      "Prediction is: 0\n",
      "189\n",
      "Prediction is: 1\n",
      "190\n",
      "Prediction is: 3\n",
      "191\n",
      "Prediction is: 7\n",
      "192\n",
      "Prediction is: 9\n",
      "193\n",
      "Prediction is: 1\n",
      "194\n",
      "Prediction is: 7\n",
      "195\n",
      "Prediction is: 0\n",
      "196\n",
      "Prediction is: 1\n",
      "197\n",
      "Prediction is: 6\n",
      "198\n",
      "Prediction is: 4\n",
      "199\n",
      "Prediction is: 6\n",
      "64.5\n",
      "1.3998752357065678\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "num_examples = 200\n",
    "rand = 1000\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "import IPython\n",
    "y = np.zeros((10,num_examples))\n",
    "val_loss = 0\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "def imshow(img):\n",
    "    _,ret = cv2.imencode('.jpg', img)\n",
    "    i = IPython.display.Image(data=ret)\n",
    "    IPython.display.display(i)\n",
    "x_input = x_test[rand:num_examples+rand,:,:]\n",
    "x_input = torch.FloatTensor(x_input)\n",
    "for i in range(y.shape[1]):\n",
    "    y[y_test[i+rand],i] = 1\n",
    "    y_val = Variable(torch.FloatTensor(y))\n",
    "for index in range(num_examples):\n",
    "    print(index)\n",
    "    X = x_input[index,:,:]\n",
    "    y = np.array(torch.Tensor(y_val[:,index]))\n",
    "    X = torch.reshape(X,(1,X.shape[0],X.shape[1]))\n",
    "    # X = torch.reshape(y,(1,X.shape[0],X.shape[1]))\n",
    "    X_im2col,imX1 = im2col2d(X,kernel_shape1,stride1,im_needed = False,shape_specified = True)\n",
    "    X_1 = relu(BatchNorm(torch.t(X_im2col).mm(weights1) + bias1))\n",
    "    X_1 = torch.reshape(X_1,output_shape1)\n",
    "    X_1_im2col, imX2 = im2col2d(X_1,kernel_shape2,stride2,im_needed = False,shape_specified = True)\n",
    "    X_2 = relu(BatchNorm(torch.t(X_1_im2col).mm(weights2) + bias2))\n",
    "    X_2 = torch.reshape(X_2,output_shape2)\n",
    "    X_2_im2col, imX3 = im2col2d(X_2,kernel_shape3,stride3,im_needed = False,shape_specified = True)\n",
    "    X_3 = BatchNorm(torch.t(X_2_im2col).mm(weights3) + bias3)\n",
    "    X_x = X_3.squeeze()\n",
    "    y_pred = np.array(softmax(X_x))\n",
    "    val_loss += cross_entropy(y_pred.squeeze(),y.squeeze())\n",
    "    prediction = np.argmax(y_pred,axis=0)\n",
    "    actual = np.argmax(y,axis=0)\n",
    "    print(\"Prediction is: {}\".format(prediction))\n",
    "    if prediction == actual:\n",
    "        num_correct += 1\n",
    "    if prediction == 5:\n",
    "        imshow(np.array(X.squeeze()))\n",
    "accuracy = num_correct / num_examples\n",
    "accuracy *= 100\n",
    "print(accuracy)\n",
    "print(val_loss/num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = softmax(X_2)\n",
    "\n",
    "# z = cross_entropy(y,y_pred) = sum(-y*log(y_pred))\n",
    "\n",
    "# dz/X_2 = softmax(X_2) - y\n",
    "\n",
    "# X_2 = X_im2col2'*weights2                       X_2 is not softmaxed\n",
    "\n",
    "# dX_2/dweights2 = X_im2col2'\n",
    "\n",
    "# X_im2col2 = relu(bn(X_im2col1'*weights1)\n",
    "\n",
    "# X_1 = col2im(X_im2col2)\n",
    "\n",
    "# dz/weights2 = dz/dX_2*dX_2/dweights2\n",
    "\n",
    "# dz/weights1 = dz/dX_2*dX_2/dX_im2col2*dX_im2col2/dweights1\n",
    "\n",
    "# dX_2/X_im2col2 = weights2'\n",
    "\n",
    "# dz/weights1 = dz/dX_2*weights2'*relu(X_im2col1')\n",
    "\n",
    "# X_2'*X1_im2col' = dW\n",
    "\n",
    "# dX_col = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1, bias1 = weights['layer1']\n",
    "weights2, bias2 = weights['layer2']\n",
    "weights3, bias3 = weights['layer3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.39999999999999\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('Vanilla_CNN_MNIST_weights_80%val','wb') as f:\n",
    "    pickle.dump(weights_bias,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n"
     ]
    }
   ],
   "source": [
    "a = X_1_im2col\n",
    "a = a.detach().numpy()\n",
    "a = np.array(a)\n",
    "print(a.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6eb30d34c2c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "print(y_pred,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_bias = {'layer1': [weights1,bias1],'layer2':[weights2,bias2],'layer3':[weights3,bias3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'im2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-682892365d99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'im2' is not defined"
     ]
    }
   ],
   "source": [
    "print(im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_printoptions(threshold=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(threshold=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
